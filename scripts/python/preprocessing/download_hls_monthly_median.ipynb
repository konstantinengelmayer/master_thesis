{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "\n",
    "# Initialize the Earth Engine API\n",
    "ee.Initialize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the merged HLS collection: 3428\n",
      "Example image: {'type': 'Image', 'bands': [{'id': 'Blue', 'data_type': {'type': 'PixelType', 'precision': 'double', 'min': -3.2768, 'max': 3.2767}, 'dimensions': [3660, 3660], 'crs': 'EPSG:32631', 'crs_transform': [30, 0, 699960, 0, -30, 5600040]}, {'id': 'Green', 'data_type': {'type': 'PixelType', 'precision': 'double', 'min': -3.2768, 'max': 3.2767}, 'dimensions': [3660, 3660], 'crs': 'EPSG:32631', 'crs_transform': [30, 0, 699960, 0, -30, 5600040]}, {'id': 'Red', 'data_type': {'type': 'PixelType', 'precision': 'double', 'min': -3.2768, 'max': 3.2767}, 'dimensions': [3660, 3660], 'crs': 'EPSG:32631', 'crs_transform': [30, 0, 699960, 0, -30, 5600040]}, {'id': 'NIR', 'data_type': {'type': 'PixelType', 'precision': 'double', 'min': -3.2768, 'max': 3.2767}, 'dimensions': [3660, 3660], 'crs': 'EPSG:32631', 'crs_transform': [30, 0, 699960, 0, -30, 5600040]}, {'id': 'SWIR1', 'data_type': {'type': 'PixelType', 'precision': 'double', 'min': -3.2768, 'max': 3.2767}, 'dimensions': [3660, 3660], 'crs': 'EPSG:32631', 'crs_transform': [30, 0, 699960, 0, -30, 5600040]}, {'id': 'SWIR2', 'data_type': {'type': 'PixelType', 'precision': 'double', 'min': -3.2768, 'max': 3.2767}, 'dimensions': [3660, 3660], 'crs': 'EPSG:32631', 'crs_transform': [30, 0, 699960, 0, -30, 5600040]}, {'id': 'Cirrus', 'data_type': {'type': 'PixelType', 'precision': 'double', 'min': -3.2768, 'max': 3.2767}, 'dimensions': [3660, 3660], 'crs': 'EPSG:32631', 'crs_transform': [30, 0, 699960, 0, -30, 5600040]}, {'id': 'Fmask', 'data_type': {'type': 'PixelType', 'precision': 'int', 'min': 0, 'max': 255}, 'dimensions': [3660, 3660], 'crs': 'EPSG:32631', 'crs_transform': [30, 0, 699960, 0, -30, 5600040]}], 'version': 1738130032768474, 'id': 'NASA/HLS/HLSS30/v002/T31UGR_20151217T103442', 'properties': {'system:index': '1_T31UGR_20151217T103442', 'MSI_BAND_01_BANDPASS_ADJUSTMENT_SLOPE': 0.9959, 'AROP_NCP': 0, 'B1_scale': 0.0001, 'MSI_BAND_12_BANDPASS_ADJUSTMENT_SLOPE': 1.003, 'B8_scale': 0.0001, 'HLS_PROCESSING_TIME': '2023-06-14T23:14:45Z', 'B4_scale': 0.0001, 'MEAN_VIEW_AZIMUTH_ANGLE': 105.94423271, 'system:footprint': {'type': 'LinearRing', 'coordinates': [[5.820350030049639, 50.51815762606059], [5.820344659603282, 50.51812382502856], [5.763144642364269, 49.53202387675575], [5.763306552855847, 49.531895546413196], [5.763442383642115, 49.53175503217099], [5.763510241061311, 49.531744947590404], [7.276957170311932, 49.48563517035979], [7.277157936824502, 49.48573760200643], [7.277376899370169, 49.48582296788166], [7.277393732758589, 49.48586677325377], [7.320960236825879, 49.97816034889527], [7.365744675423007, 50.470360718083676], [7.36558407350662, 50.470491253494366], [7.3654505176496725, 50.47063355878691], [7.36538160125364, 50.47064467508821], [5.820785179755994, 50.51838345696196], [5.820582999791318, 50.5182785265642], [5.820361900084992, 50.51819046811377], [5.820350030049639, 50.51815762606059]]}, 'MEAN_SUN_ZENITH_ANGLE': 74.17952647, 'MSI_BAND_02_BANDPASS_ADJUSTMENT_SLOPE': 0.9778, 'MSI_BAND_8A_BANDPASS_ADJUSTMENT_SLOPE': 0.9983, 'CLOUD_COVERAGE': 98, 'MSI_BAND_03_BANDPASS_ADJUSTMENT_SLOPE': 1.0053, 'PRODUCT_URI': 'S2A_MSIL1C_20151217T103442_N0201_R108_T31UGR_20151217T103436.SAFE', 'MSI_BAND_04_BANDPASS_ADJUSTMENT_OFFSET': 0.0009, 'SPATIAL_COVERAGE': 58, 'system:time_end': 1450434882000, 'MSI_BAND_8A_BANDPASS_ADJUSTMENT_OFFSET': -0.0001, 'B8A_scale': 0.0001, 'MSI_BAND_01_BANDPASS_ADJUSTMENT_OFFSET': -0.0002, 'system:time_start': 1450348482000, 'MSI_BAND_12_BANDPASS_ADJUSTMENT_OFFSET': -0.0012, 'B9_scale': 0.0001, 'MSI_BAND_04_BANDPASS_ADJUSTMENT_SLOPE': 0.9765, 'VZA_scale': 0.01, 'ACCODE': 'LaSRC v3.2.0', 'AROP_AVE_XSHIFT': 0, 'MSI_BAND_11_BANDPASS_ADJUSTMENT_SLOPE': 0.9987, 'B3_scale': 0.0001, 'PROCESSING_BASELINE': ['02.01'], 'NBAR_SOLAR_ZENITH': 74.39075892, 'B12_scale': 0.0001, 'B6_scale': 0.0001, 'B11_scale': 0.0001, 'MSI_BAND_02_BANDPASS_ADJUSTMENT_OFFSET': -0.004, 'MEAN_SUN_AZIMUTH_ANGLE': 167.74433606, 'AROP_AVE_YSHIFT': 0, 'SAA_scale': 0.01, 'MSI_BAND_03_BANDPASS_ADJUSTMENT_OFFSET': -0.0009, 'B2_scale': 0.0001, 'MSI_BAND_11_BANDPASS_ADJUSTMENT_OFFSET': -0.0011, 'B7_scale': 0.0001, 'B10_scale': 0.0001, 'MGRS_TILE_ID': '31UGR', 'B5_scale': 0.0001, 'AROP_RMSE': 0, 'SZA_scale': 0.01, 'MEAN_VIEW_ZENITH_ANGLE': 9.39043419, 'system:asset_size': 207238276, 'VAA_scale': 0.01}}\n",
      "Number of monthly median images: 146\n",
      "Exporting HLS Monthly Median for 2013-01 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2013-02 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2013-03 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2013-04 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2013-05 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2013-06 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2013-07 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2013-08 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2013-09 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2013-10 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2013-11 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2013-12 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2014-01 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2014-02 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2014-03 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2014-04 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2014-05 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2014-06 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2014-07 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2014-08 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2014-09 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2014-10 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2014-11 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2014-12 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2015-01 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2015-02 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2015-03 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2015-04 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2015-05 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2015-06 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2015-07 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2015-08 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2015-09 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2015-10 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2015-11 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2015-12 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2016-01 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2016-02 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2016-03 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2016-04 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2016-05 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2016-06 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2016-07 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2016-08 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2016-09 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2016-10 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2016-11 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2016-12 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2017-01 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2017-02 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2017-03 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2017-04 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2017-05 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2017-06 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2017-07 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2017-08 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2017-09 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2017-10 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2017-11 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2017-12 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2018-01 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2018-02 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2018-03 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2018-04 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2018-05 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2018-06 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2018-07 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2018-08 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2018-09 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2018-10 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2018-11 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2018-12 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2019-01 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2019-02 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2019-03 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2019-04 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2019-05 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2019-06 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2019-07 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2019-08 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2019-09 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2019-10 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2019-11 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2019-12 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2020-01 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2020-02 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2020-03 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2020-04 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2020-05 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2020-06 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2020-07 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2020-08 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2020-09 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2020-10 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2020-11 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2020-12 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2021-01 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2021-02 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2021-03 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2021-04 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2021-05 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2021-06 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2021-07 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2021-08 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2021-09 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2021-10 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2021-11 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2021-12 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2022-01 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2022-02 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2022-03 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2022-04 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2022-05 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2022-06 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2022-07 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2022-08 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2022-09 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2022-10 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2022-11 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2022-12 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2023-01 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2023-02 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2023-03 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2023-04 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2023-05 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2023-06 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2023-07 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2023-08 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2023-09 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2023-10 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2023-11 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2023-12 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2024-01 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2024-02 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2024-03 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2024-04 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2024-05 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2024-06 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2024-07 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2024-08 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2024-09 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2024-10 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2024-11 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2024-12 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2025-01 to Google Drive...\n",
      "Exporting HLS Monthly Median for 2025-02 to Google Drive...\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import json\n",
    "\n",
    "# Load the shapefile using GeoPandas to define the area of interest (AOI)\n",
    "gdf = gpd.read_file(r\"C:\\Users\\konst\\Documents\\Hiwi\\mw3\\drought_indicies\\data\\Untersuchungsgebiete\\002a_Sen1-Subset_Eifel.shp\")\n",
    "\n",
    "# Convert the shapefile to GeoJSON format for compatibility with Earth Engine\n",
    "geojson = gdf.to_json()\n",
    "\n",
    "# Convert the GeoJSON geometry to an Earth Engine Geometry object\n",
    "aoi = ee.Geometry(json.loads(geojson)['features'][0]['geometry'])\n",
    "\n",
    "# Define the date range for filtering the datasets\n",
    "start_date = '2013-01-01'\n",
    "end_date = '2025-01-31'\n",
    "\n",
    "# Define a cloud masking function for filtering out clouds and cloud shadows in images\n",
    "def mask_clouds(image):\n",
    "    # Select the Fmask band, which contains cloud-related information\n",
    "    fmask = image.select('Fmask')\n",
    "    \n",
    "    # Extract the cloud bit (bit 1) and shadow bit (bit 3) from the Fmask band\n",
    "    cloud_bit = fmask.rightShift(1).bitwiseAnd(1)  # Bit 1 (cloud)\n",
    "    adjacent_bit = fmask.rightShift(2).bitwiseAnd(1) # Bit 2 (adjacent to clouds, unused)\n",
    "    shadow_bit = fmask.rightShift(3).bitwiseAnd(1)  # Bit 3 (shadow)\n",
    "    \n",
    "    # Create a mask that excludes pixels where cloud_bit or shadow_bit is 1 (cloudy or shadowed)\n",
    "    mask = cloud_bit.eq(0).And(shadow_bit.eq(0))\n",
    "    \n",
    "    # Return the image with the mask applied\n",
    "    return image.updateMask(mask)\n",
    "\n",
    "# Load and filter the Landsat-based HLS (HLSL30) dataset\n",
    "hlsl30 = (\n",
    "    ee.ImageCollection('NASA/HLS/HLSL30/v002')  # Landsat-based HLS dataset\n",
    "    .filterBounds(aoi)                         # Filter images by the AOI\n",
    "    .filterDate(start_date, end_date)          # Filter images by the date range\n",
    "    .map(mask_clouds)                          # Apply the cloud masking function\n",
    ")\n",
    "\n",
    "# Load and filter the Sentinel-2-based HLS (HLSS30) dataset\n",
    "hlss30 = (\n",
    "    ee.ImageCollection('NASA/HLS/HLSS30/v002')  # Sentinel-2-based HLS dataset\n",
    "    .filterBounds(aoi)                          # Filter images by the AOI\n",
    "    .filterDate(start_date, end_date)           # Filter images by the date range\n",
    "    .map(mask_clouds)                           # Apply the cloud masking function\n",
    ")\n",
    "\n",
    "hlss30_renamed = hlss30.map(lambda img: img.select(\n",
    "    ['B2', 'B3', 'B4', 'B8A', 'B11', 'B12', 'B10','Fmask'],\n",
    "    ['Blue','Green','Red','NIR','SWIR1','SWIR2','Cirrus','Fmask']\n",
    "))\n",
    "\n",
    "hlsl30_renamed = hlsl30.map(lambda img: img.select(\n",
    "    ['B2','B3','B4','B5','B6','B7','B9','Fmask'],\n",
    "    ['Blue','Green','Red','NIR','SWIR1','SWIR2','Cirrus','Fmask']\n",
    "))\n",
    "\n",
    "hls_col = hlss30_renamed.merge(hlsl30_renamed)\n",
    "\n",
    "# Debugging: Print the number of images in the merged collection and an example image\n",
    "print('Number of images in the merged HLS collection:', hls_col.size().getInfo())\n",
    "print('Example image:', hls_col.first().getInfo())\n",
    "\n",
    "# Function to group the collection by month and calculate the median for each month\n",
    "def calculate_monthly_medians(collection, start_date, end_date):\n",
    "    # Generate a list of months within the date range\n",
    "    months = ee.List.sequence(0, ee.Date(end_date).difference(ee.Date(start_date), 'month').round())\n",
    "\n",
    "    # Function to calculate the median for a specific month\n",
    "    def get_monthly_median(month):\n",
    "        # Define the start and end dates for the current month\n",
    "        start_month = ee.Date(start_date).advance(month, 'month')\n",
    "        end_month = start_month.advance(1, 'month')\n",
    "        \n",
    "        # Filter the collection to include only images within the current month\n",
    "        filtered = collection.filterDate(start_month, end_month)\n",
    "        \n",
    "        # Calculate the median for the filtered collection and set metadata\n",
    "        median = filtered.median().set({\n",
    "            'month': start_month.format('YYYY-MM'),  # Add month metadata\n",
    "            'system:time_start': start_month.millis()  # Add timestamp metadata\n",
    "        })\n",
    "        \n",
    "        return median\n",
    "\n",
    "    # Map the median calculation function over the list of months\n",
    "    return ee.ImageCollection.fromImages(months.map(get_monthly_median))\n",
    "\n",
    "# Calculate the monthly median images for the merged collection\n",
    "monthly_medians = calculate_monthly_medians(hls_col, start_date, end_date)\n",
    "\n",
    "# Debugging: Print the number of monthly median images\n",
    "print('Number of monthly median images:', monthly_medians.size().getInfo())\n",
    "\n",
    "# Function to export the monthly median images to Google Drive\n",
    "def export_monthly_medians(collection, aoi, folder_name='HLS_Monthly_Medians', scale=30):\n",
    "    # Convert the collection to a list of images for iteration\n",
    "    collection_list = collection.toList(collection.size())\n",
    "    \n",
    "    # Iterate through the collection and export each image\n",
    "    for i in range(collection.size().getInfo()):\n",
    "        # Get the current image\n",
    "        image = ee.Image(collection_list.get(i))\n",
    "        # Retrieve the month metadata\n",
    "        month = image.get('month').getInfo()\n",
    "        \n",
    "        # Create and start the export task\n",
    "        task = ee.batch.Export.image.toDrive(\n",
    "            image=image.clip(aoi),  # Clip the image to the AOI\n",
    "            description=f'HLS_Monthly_Median_{month}',  # Task description\n",
    "            folder=folder_name,  # Google Drive folder name\n",
    "            fileNamePrefix=f'HLS_Monthly_Median_{month}',  # File name prefix\n",
    "            region=aoi.bounds().getInfo()['coordinates'],  # AOI boundaries\n",
    "            scale=scale,  # Spatial resolution\n",
    "            maxPixels=1e13  # Maximum allowable pixels\n",
    "        )\n",
    "        task.start()\n",
    "        print(f'Exporting HLS Monthly Median for {month} to Google Drive...')\n",
    "\n",
    "# Export the monthly median images\n",
    "export_monthly_medians(monthly_medians, aoi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray as rxr\n",
    "import xarray as xr\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "# 1) Folder with all your .tif files\n",
    "folder = \"C:/Users/konst/Documents/Hiwi/mw3/master_thesis/data/satellite_data/hls_eifel/raw/\"\n",
    "\n",
    "# 2) Get list of all .tif files\n",
    "tif_files = sorted(glob.glob(os.path.join(folder, \"*.tif\")))\n",
    "\n",
    "# 3) Define band names mapping\n",
    "band_names = {\n",
    "    1: 'Blue',\n",
    "    2: 'Green',\n",
    "    3: 'Red',\n",
    "    4: 'NIR',\n",
    "    5: 'SWIR1',\n",
    "    6: 'SWIR2',\n",
    "    7: 'Cirrus',\n",
    "    8: 'Fmask'\n",
    "}\n",
    "\n",
    "# 4) Function to extract date from filename\n",
    "def extract_date(filename):\n",
    "    # Adjust this regex pattern to match your filename format\n",
    "    pattern = r'(\\d{4}-\\d{2})'\n",
    "    match = re.search(pattern, filename)\n",
    "    if match:\n",
    "        return pd.to_datetime(match.group(1))\n",
    "    raise ValueError(f\"Could not extract date from filename: {filename}\")\n",
    "\n",
    "# 5) Read all files and create a list of datasets\n",
    "datasets = []\n",
    "for file in tif_files:\n",
    "    # Read the file\n",
    "    ds = rxr.open_rasterio(file)\n",
    "    \n",
    "    # Extract date from filename\n",
    "    date = extract_date(file)\n",
    "    \n",
    "    # Convert band dimension to variables\n",
    "    ds = ds.to_dataset(dim='band')\n",
    "    \n",
    "    # Rename variables using the band_names mapping\n",
    "    ds = ds.rename({i: band_names[i] for i in range(1, 9)})\n",
    "    \n",
    "    # Add time coordinate\n",
    "    ds = ds.expand_dims(time=[date])\n",
    "    \n",
    "    datasets.append(ds)\n",
    "\n",
    "# 6) Combine all datasets\n",
    "combined_ds = xr.concat(datasets, dim='time')\n",
    "\n",
    "# 7) Add metadata\n",
    "combined_ds.attrs['title'] = 'Combined satellite data'\n",
    "combined_ds.attrs['creation_date'] = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "# Loop through each variable in the dataset\n",
    "for var in combined_ds.data_vars:\n",
    "    combined_ds[var] = combined_ds[var].where((combined_ds[var] > 0) & np.isfinite(combined_ds[var]), np.nan)\n",
    "\n",
    "# 7) Save to NetCDF\n",
    "output_file = os.path.join(folder, 'HLS_Monthly_Medians_2013-04_2025-01.nc')\n",
    "combined_ds.to_netcdf(output_file)\n",
    "\n",
    "# 8) Close all datasets\n",
    "for ds in datasets:\n",
    "    ds.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KeysView(<xarray.Dataset> Size: 8GB\n",
       "Dimensions:      (time: 142, y: 612, x: 1394)\n",
       "Coordinates:\n",
       "  * time         (time) datetime64[ns] 1kB 2013-04-01 2013-05-01 ... 2025-01-01\n",
       "  * x            (x) float64 11kB 6.284 6.284 6.285 6.285 ... 6.659 6.659 6.66\n",
       "  * y            (y) float64 5kB 50.64 50.64 50.64 50.64 ... 50.48 50.48 50.48\n",
       "    spatial_ref  int64 8B 0\n",
       "Data variables:\n",
       "    1            (time, y, x) float64 969MB nan nan nan nan ... nan nan nan nan\n",
       "    2            (time, y, x) float64 969MB nan nan nan nan ... nan nan nan nan\n",
       "    3            (time, y, x) float64 969MB nan nan nan nan ... nan nan nan nan\n",
       "    4            (time, y, x) float64 969MB nan nan nan nan ... nan nan nan nan\n",
       "    5            (time, y, x) float64 969MB nan nan nan nan ... nan nan nan nan\n",
       "    6            (time, y, x) float64 969MB nan nan nan nan ... nan nan nan nan\n",
       "    7            (time, y, x) float64 969MB nan nan nan nan ... nan nan nan nan\n",
       "    8            (time, y, x) float64 969MB nan nan nan nan ... nan nan nan nan\n",
       "Attributes:\n",
       "    AREA_OR_POINT:  Area\n",
       "    scale_factor:   1.0\n",
       "    add_offset:     0.0\n",
       "    long_name:      ('Blue', 'Green', 'Red', 'NIR', 'SWIR1', 'SWIR2', 'Cirrus...\n",
       "    title:          Combined satellite data\n",
       "    creation_date:  2025-01-30)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_ds.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CIS_WS24_25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
